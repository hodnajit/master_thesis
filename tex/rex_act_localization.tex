\label[chap-rloc]
\chap Localization system design and implementation
In this chapter, the design of the architecture is described along with the tools used in its solution.

The first part proposes the system architecture design and the system kinematics equations follow in the second part. In the third part, the equations for the Error state extended Kalman filter are introduced. The fourth part is dedicated to injecting the estimated error into the estimated state and resetting the injected error. In the fifth and final part, the implementation tools are discussed.

To sum up, this chapter gives the reader a detailed introduction to the proposed localization system with all of the equations and tools used in the final implementation.

\sec System architecture design
Various approaches for state estimation were introduced in Chapter \ref[chap-state-est]. The chosen approach is the Error state extended Kalman filter (ES-EKF). According to ES-EKF, the states' error is estimated using a Kalman filter rather than the state itself. The benefits of this approach are briefly summarized in Chapter \ref[chap-state-est].

The system consists of three crucial steps. The first is the inertial navigation system (INS), where the state is estimated based on IMU measurements. This state estimation leads to a dead-reckoning system, where the drift grows with time and needs to be corrected.

The second step is the ES-EKF itself. The error of the state is calculated and is then corrected using measurements from UWB localization and odometry. Measurements from UWB localization and odometry observe the error. The UWB localization gives the absolute position, which can reduce the drift in step one.

The third part is injecting the error into INS estimation and resetting the ES-EKF while the injection is done. Finally, the output of the whole system is given by the INS solution. The system requires initial states with covariances for INS and ES-EKF set up first. The simplified architecture is illustrated in Figure \ref[fig-architecture] and described in the following section in detail.

\midinsert
\picw=\hsize \cinspic imgs/rex_act_localization/architecture.pdf
\clabel[fig-architecture]{The proposed architecture of the localization system.}
\caption/f The proposed architecture of the localization system.
\endinsert

For navigation purposes, the usual rate of pose estimation is hundreds of Hertz \cite[vehicle_state_estimation_farrel]. The INS provides a full state estimate with the IMU update rate, which usually satisfies this requirement.
Furthermore, it gives us the state estimation independent of external factors, such as wheel slippage \cite[vehicle_state_estimation_farrel].

UWB localization and odometry measurements cannot give us a much higher rate than tens Hertz, and they are used only in the correction step.

In other words, the most dynamic part of the estimation is somehow independent of Kalman filtering. On the one hand, the state estimation in INS is fast and straightforward. On the other hand, the error estimation can be more computationally demanding as the computation of Jacobians needs to be done. Therefore, the separation of the state estimation and the error estimation makes the calculation of the state sufficiently fast enough for our purposes. The error state is estimated separately in ES-EKF and is injected into the state only if another measurement other than IMU comes in. The only requirement is that the correction must be applied before non-Gaussian noise in IMU measurement is significant. That correction compensates for the drift of the dead-reckoning system.

In conclusion, the benefit of this architecture is state estimation at a high rate, independent of external events. The state is corrected at a lower rate but faster than the non-Gaussian noise becomes significant in state estimation. That brings the best aspects of all of the types of sensors, which are used in the architecture.

In the following sections, the output of the system is called the navigation state (i.e., position, linear velocity, and attitude).

\sec System kinematics
For a more detailed introduction to system architecture, the system kinematics equations need to be announced. Equations are taken from \cite[quaternion_kinematics], but instead of using GNSS, it uses UWB localization and linear velocity from odometry.

But before I enter that itself, let me describe an important topic, which represents attitude and rotation in 3D space.
\secc Representation of 3D attitude and rotation in space
There are many ways to represent 3D attitude and rotation in space. The most commonly used representations in the field of robotics are
	\begitems
		* rotation matrices,
		* Euler angles,
		* axis-angle
		* and quaternions \cite[handbook_robotics].
	\enditems
To not go into too much detail, each representation has its pros and cons and applications, where it has its purpose. The rotation matrix is chosen as the internal representation of orientation and the quaternion as an output.

There are several reasons to pick this representation \cite[orientation_representation, ros_rep103].
Firstly, quaternions and rotation matrices do not suffer from singularities as Euler and fixed angles do \cite[orientation_representation]. Secondly, quaternion gives us a compact representation. And finally, these two are the most recommended representation in ROS standard rep-103 \cite[ros_rep103]. As quaternions have many internal models in different libraries (Eigen library in C++ \cite[eigenweb], geometry messages library \cite[ros_geometry_msgs] or the transform library tf2 in ROS \cite[ros_tf2]) and the representation is not easy to imagine, I decided to use the quaternions only as an output and rotation matrix as the internal representation.

\secc The kinematic equations in continuous time
The kinematics formulas in continuous time, that relate the inertial sensor measurements to the {\bf true navigation state}, are well-known \cite[quaternion_kinematics, farrell_aided, mems_navigation, handbook_gnss_ins]. Therefore, I did not have to derive equations myself and used the one derived in \cite[quaternion_kinematics] equation 235.

The only difference is that orientation is in the rotation matrix and not quaternion. Equations are
$$	\eqalign{\dot{{\bf p_t}} &= {\bf v_t} \cr
			 \dot{{\bf v_t}} &= {\bf R_t}({\bf a_m}-{\bf a_{bt}}-{\bf a_n}) + {\bf g_t} \cr
			 \dot{{\bf R_t}} &= {\bf R_t}({\bf \Omega_t}) \cr
			 \dot{{\bf a_{bt}}} &= {\bf a_w} \cr
			 \dot{{\bf \omega_{bt}}} &= {\bf \omega_w} \cr
			 \dot{{\bf g_t}} &= {\bf 0},
			 } \eqmark
$$
where
\begitems
* ${\bf p_t}$ is the true position in 3D [$m$],
* ${\bf v_t}$ is the true linear velocity in 3D [$m \cdot s^{-2}$],
* ${\bf R_t}$ is the true rotation matrix of orientation,
* ${\bf a_m}$ is the specific force given by accelerometers [$m \cdot s^{-2}$],
* ${\bf a_{bt}}$ is the true accelerometer bias [$m \cdot s^{-2}$],
* ${\bf a_n}$ is the accelerometers white Gaussian noise [$m \cdot s^{-2}$],
* ${\bf a_w}$ is the white Gaussian noise accelerometers bias [$m \cdot s^{-2}$],
* ${\bf g_t}$ is the true gravity vector [$m \cdot s^{-2}$],
* ${\bf \Omega_t }=\left[ ({\bf \omega_m} - {\bf \omega_{bt}} - {\bf \omega_n})_{\times} \right] = \left[
 \matrix{0 & -(\omega_{m_3} - \omega_{bt_3} - \omega_{n_3}) & \omega_{m_2} - \omega_{bt_2} - \omega_{n_2} \cr
         \omega_{m_3} - \omega_{bt_3} - \omega_{n_3} & 0 & -(\omega_{m_1} - \omega_{bt_1} - \omega_{n_1}) \cr
         -(\omega_{m_2} - \omega_{bt_2} - \omega_{n_2}) & \omega_{m_1} - \omega_{bt_1} - \omega_{n_1} & 0
}  \right]$ is the true skew-symmetric matrix (a tensor of angular velocity) [$rad \over s$],
* ${\bf \omega_m}$ is the angular rate given by gyroscopes [$rad \over s$],
* ${\bf \omega_{bt}}$ is the true bias of gyroscopes [$rad \over s$],
* ${\bf \omega_n}$ is the gyroscope's white Gaussian noise [$rad \over s$],
* and ${\bf \omega_w}$ is the white Gaussian noise gyroscope's bias [$rad \over s$].
\enditems

The state ${\bf x_t}$, is governed by IMU noisy reading ${\bf u_m}$ and perturbed by the white Gaussian noise ${\bf w}$, defined by
$$ \eqalign{{\bf x_t} &= \left[ {\bf p_t}, {\bf v_t}, {\bf R_t}, {\bf a_{bt}}, {\bf \omega_{bt}}, {\bf g_t}\right]^T \cr
			{\bf u_t} &= \left[ {\bf a_m}-{\bf a_n}\right]^T \cr
			{\bf w_t} &= \left[ {\bf a_w}, {\bf w_w}\right]^T.}\eqmark$$
			

The output of the localization system is {\bf navigation state} (also called nominal), which corresponds to the system kinematics, but does not take into account the noise terms $w_t$ and other possible model imperfections (see equation 237 in \cite[quaternion_kinematics], hence it is simplified to
	$$	\eqalign{
		{\bf \dot{p}} &= {\bf v} \cr
		{\bf \dot{v}} &= {\bf R(a_m-a_{b})} + {\bf g} \cr
		{\bf \dot{R}} &= {\bf R(\Omega)} \cr
		{\bf \dot{a_{b}}} &= {\bf 0} \cr
		{\bf \dot{\omega_{b}}} &= {\bf 0},	\cr
		{\bf \dot{g}} &= {\bf 0},	 
	}
	\eqmark
	$$
where
\begitems
* ${\bf p}$ is the position in 3D [$m$],
* ${\bf v}$ is the linear velocity in 3D [$m \cdot s^{-2}$],
* ${\bf R}$ is the rotation matrix of orientation,
* ${\bf a_m}$ is the specific force given by accelerometers [$m \cdot s^{-2}$],
* ${\bf a_{b}}$ is the accelerometer bias [$m \cdot s^{-2}$],
* ${\bf g}$ is the gravity vector [$m \cdot s^{-2}$],
* ${\bf \Omega}=\left[ ({\bf \omega_m} - {\bf \omega_{b}})_{\times} \right] = \left[
 \matrix{0 & -(\omega_{m_3} - \omega_{b_3}) & \omega_{m_2} - \omega_{b_2}  \cr
         \omega_{m_3} - \omega_{b_3} & 0 & -(\omega_{m_1} - \omega_{b_1}) \cr
         -(\omega_{m_2} - \omega_{b_2}) & \omega_{m_1} - \omega_{b_1} & 0
}  \right]$ is the skew-symmetric matrix (a tensor of angular velocity) [$rad \over s$],
* ${\bf \omega_m}$ is the angular rate given by gyroscopes [$rad \over s$],
* ${\bf \omega_{b}}$ is the bias of gyroscopes [$rad \over s$].
\enditems

The linearized dynamics (see equation 238 in \cite[quaternion_kinematics]) of the {\bf error state} are
$$
\eqalign{
	{\bf \dot{\delta p}} &= {\bf \delta v} \cr
	{\bf \dot{\delta v}} &= -{\bf R}[{\bf a_m}-{\bf a_b}]_{\times} {\bf \delta \Theta} - {\bf R} {\bf \delta a_b} + {\bf \delta g} - {\bf R a_n} \cr
	{\bf \dot{\delta \Theta}} &= -[{\bf \omega_m} - {\bf \omega_b}]_{\times} {\bf \delta \Theta} - {\bf \delta \omega_b} - {\bf \omega_n} \cr
	{\bf \dot{\delta a_b}} &= {\bf a_w} \cr
	{\bf \dot{\delta \omega_b}} &= {\bf \omega_w} \cr
	{\bf \dot{\delta g}} &= {\bf 0} 
,}
\eqmark
$$
where
\begitems
* ${\bf \delta p}$ is the position error in [$m$],
* ${\bf \delta v}$ is the linear velocity error in [$m \cdot s^{-2}$],
* ${\bf \delta\Theta}$ is the orientation error,
* ${\bf \delta a_b}$ is the acceleration bias error [$m \cdot s^{-2}$],
* ${\bf \delta \omega_b}$ is the gyroscope bias error [$rad \over s$],
* ${\bf \delta g}$ is the gravity vector error [$m \cdot s^{-2}$],
* ${\bf R}$ is the rotation matrix given by the nominal state,
* ${\bf a_m}$ is the specific force given by accelerometers [$m \cdot s^{-2}$],
* ${\bf a_{b}}$ is the accelerometer bias [$m \cdot s^{-2}$],
* ${\bf a_n}$ is the accelerometers white Gaussian noise [$m \cdot s^{-2}$],
* ${\bf a_w}$ is the white Gaussian noise accelerometers bias [$m \cdot s^{-2}$],
* ${\bf \omega_m}$ is the angular rate given by gyroscopes [$rad \over s$],
* ${\bf \omega_{b}}$ is the bias of gyroscopes [$rad \over s$],
* ${\bf \omega_n}$ is the gyroscopes white Gaussian noise [$rad \over s$],
* and ${\bf \omega_w}$ is the white Gaussian noise gyroscopes bias [$rad \over s$].
\enditems
Note that higher orders in linearization are neglected since the error state is small compared to the navigation state.

During the {\bf filter correction phase}, measurements from UWB localization and odometry come into account. Usual, the sensor delivers measurements that depend on the state, such as
$$
{\bf y} = h({\bf x_t}) + {\bf \rho} ,
\eqmark
$$
where
\begitems
*$h(t)$ is a general nonlinear function of the system state (the true navigation state)
* and ${\bf \rho}$ is a white Gaussian noise with covariance.
For {\it UWB localization}, the function is simple as it is
$$
{\bf y_1} = {\bf p_t} + {\bf \rho_1},
\eqmark
$$
with covariance ${\bf R_1}$.
But for {\it odometry}, it is a little bit complicated
\label[eq-uwb_loc]
$$
{\bf y_2} = {\bf R_t^{-1}}{\bf v_t} + {\bf \rho_2}
\eqmark
$$
with covariance ${\bf R_2}$. This difference is important in the computation of Jacobian for the ES-EKF algorithm.

\label[chap-secc-kin-discr]
\secc The kinematic equations in discrete time
As the equations in continuous time are derived from book \cite[quaternion_kinematics], where their representation in discrete time is also presented, I decided to write down only the parts that are different. For more detail, see equations 260 in \cite[quaternion_kinematics]. The equation 260c is slightly different since I am using a rotation matrix for orientation representation and not quaternion. This equation is changed to
$$
{\bf R} \leftarrow {\bf R} + ({\bf R \Omega}) {\bf \Delta t}),
\eqmark
$$
where
\begitems
* ${\bf R}$ is the rotation matrix of orientation,
* ${\bf \Omega}=\left[ ({\bf \omega_m} - {\bf \omega_{b}})_{\times} \right] = \left[
 \matrix{0 & -(\omega_{m_3} - \omega_{b_3}) & \omega_{m_2} - \omega_{b_2}  \cr
         \omega_{m_3} - \omega_{b_3} & 0 & -(\omega_{m_1} - \omega_{b_1}) \cr
         -(\omega_{m_2} - \omega_{b_2}) & \omega_{m_1} - \omega_{b_1} & 0
}  \right]$ is the skew-symmetric matrix (a tensor of angular velocity) [$rad \over s$],
* ${\bf \omega_m}$ is the angular rate given by gyroscopes [$rad \over s$],
* ${\bf \omega_{b}}$ is the bias of gyroscopes [$rad \over s$].
\enditems

This integration is happening in the INS box in Figure \ref[fig-architecture].

\sec Error state extended Kalman filter implementation
The algorithm and equations for the general extended Kalman filter are briefly described in Chapter \ref[chap-state-est]. In this section, these equations are concretized.

The { \bf error state system} is now
$$
{\bf \delta x} \leftarrow f({\bf x}, {\bf \delta x}, {\bf u_m}, {\bf i}) = F_x({\bf x}, {\bf u_m}) \cdot {\bf \delta x} + {\bf F_i} \cdot {\bf i},
\eqmark
$$
where ${\bf i}$ is a perturbation vector (usually modeled as white Gaussian noise).

The {\bf Es-EKF prediction part} is given by
$$
\eqalign{
{\bf \hat{\delta x}} &\leftarrow {\bf F_x}({\bf x}, {\bf u_m}) \cdot {\bf \hat{\delta x}} \cr
{\bf \hat{P}} &\leftarrow {\bf F_x} {\bf P} {\bf F_x^T} + {\bf F_i} {\bf Q} {\bf F_i^T}
},
\eqmark
$$
where
\begitems
* ${\bf P}$ is a process covariance matrix,
* ${\bf F_x}$ is a transition matrix,
* ${\bf F_i}$ is the Jacobian of error state system by impulses,
* ${\bf Q}$ is the covariances of process noise,
\enditems

The {\bf transition matrix}\fnote{Called system matrix in some literature} ${\bf F_x}$ is error state Jacobian and it is simply determined by error state kinematics equations $f({\bf \delta x_t})$ in discrete time in Section \ref[chap-secc-kin-discr],
$$
\eqalign{
{\bf F_x} &= {\partial f({\bf \delta x}, {\bf u_m}) \over {\partial {\bf \delta x}}}\cr
{\bf F_x} &= 
\left[
\matrix{
{\bf I} & {\bf I} \Delta t & 0 & 0 & 0 & 0 \cr
0 & {\bf I} & -{\bf R}[{\bf a_m}-{\bf a_b}]_{\times} \Delta t & -{\bf R} \Delta t & 0 & {\bf I} \Delta t \cr
0 & 0 & {\bf R\{\omega_m-\omega_b\}^T} \Delta t & 0 & -{\bf I} \Delta t & 0 \cr
0 & 0 & 0 & I & 0 & 0 \cr
0 & 0 & 0 & 0 & I & 0 \cr
0 & 0 & 0 & 0 & 0 & I}
\right].
}
\eqmark
$$

${\bf F_i}$ is given by
$$
{\bf F_i} = {\partial f \over {\partial i}} \Bigr|_{{\bf x}, {\bf u_m}} 
=
\left[
\matrix{
0 & 0 & 0 & 0\cr
I & 0 & 0 & 0 \cr
0 & I & 0 & 0 \cr
0 & 0 & I & 0 \cr
0 & 0 & 0 & I \cr
0 & 0 & 0 & 0
}
\right],
\eqmark
$$

The covariances matrix is given by random impulses applied to the velocity, orientation and bias estimates, modelled by white Gaussian noise \cite[quaternion_kinematics]
$$
{\bf Q} = \left[
\matrix{
{\bf \sigma_{a_n}^2}\Delta t^2 {\bf I} & 0 & 0 & 0\cr
0 & {\bf \sigma_{\omega_n}^2}\Delta t^2{\bf I} & 0 & 0 \cr
0 & 0 & {\bf \sigma_{a_w}^2}\Delta t^2 {\bf I} & 0 \cr
0 & 0 & 0 & {\bf \sigma_{\omega_w}^2}\Delta t^2 {\bf I}
}
\right],
\eqmark
$$
where 
\begitems
* ${\bf \sigma_{a_n}}$ is the standard deviation of accelerometers [$m \cdot s^{-2}$],
* ${\bf \sigma_{\omega_n}}$ is the standard deviation of accelerometers [$rad \over s$]
* ${\bf \sigma_{a_w}}$ is the velocity random walk [$rad \over s \sqrt{s}$],
* ${\bf \sigma_{\omega_w}}$ is the angular random walk [$rad \over s \sqrt{s}$].
\enditems
This information can be obtained from the datasheet or AVAR (see Section \ref[chap-sec-avar]).

The {\bf ES-EKF correction part} is given by
$$
\eqalign{
{\bf K} &\leftarrow {\bf P} {\bf H^T} ({\bf HPH^T} + {\bf R)^{-1}} \cr

{\bf \delta x} &\leftarrow {\bf K}({\bf y}-h({\bf \hat{x}})) \cr

{\bf P} &\leftarrow ({\bf I}-{\bf KH}) {\bf \hat{P}} ({\bf I}-{\bf KH})^T + {\bf KRK^T}
},
\eqmark
$$

where 
\begitems
* ${\bf K}$ is the Kalman gain,
* ${\bf H}$ is an observation matrix,
* ${\bf R}$ is covariances of observation noise,
* ${\bf P}$ is process covariance,
* ${\bf y}$ is an observation,
* $h({\bf \hat{x}})$ is an observation model,
* ${\bf \delta x}$ is an error state.
\enditems

The {\bf observation matrices} differ for {\it UWB localization} (${\bf H_1}$) and {\it odometry} (${\bf H_2}$)
$$
\eqalign{
{\bf H_1} &=  \left[
\matrix{
{\bf I} & 0 & 0 & 0 & 0 & 0
}
\right] \cr
{\bf H_2} &=  \left[
\matrix{
0 & {\bf R_t^{T}} & -{\bf R_t^T} [{\bf v_t}]_{\times}{\bf J_r(\Theta)} & 0 & 0 & 0 
}
\right],
}
\eqmark
$$
where
\begitems
* ${\bf R_t}$ is the orientation in navigation state,
* ${\bf v_t}$ is the linear velocity in navigation state,
* ${\bf \Theta}$ is the orientation ${\bf R_t}$ in rotation vector form,
* ${\bf J_r}$ is the right Jacobian of rotation group ${\bf SO(3)}$ (see equation 183 in \cite[quaternion_kinematics]).
\enditems
To obtain ${\bf H_2}$ from Equation \ref[eq-uwb_loc], a reader should notice a Jacobian with respect to the rotation vector in section 4.3.4 and equation 188 in \cite[quaternion_kinematics]. 

\sec Injection of the error state into the navigation state
While the correction phase is done, the estimated error state comes into account in the navigation state
$$
{\bf x} \leftarrow {\bf x} \bigoplus {\bf \delta x},
\eqmark
$$
where $\bigotimes$ appropriate composition of sums or rotation product.


The equations are
$$
\eqalign{
{\bf p} &\leftarrow {\bf p} + {\bf \delta p} \cr
{\bf v} &\leftarrow {\bf v} + {\bf \delta v} \cr
{\bf R} &\leftarrow {\bf R} * {\bf R\{\delta \Theta\}}  \cr
{\bf a_b} &\leftarrow {\bf a_b} + {\bf \delta a_b} \cr
{\bf \omega_b} &\leftarrow {\bf \omega_b} + {\bf \delta \omega_b} \cr
{\bf g} &\leftarrow {\bf g} + {\bf \delta g}
}
\eqmark
$$
where ${\bf R\{\delta \Theta\}}$ orientation error in rotation matrix.

The injection of the error state is essential, but the resetting of the error state must also be done. The ES-EKF error reset operation is
$$
\eqalign{
{\bf \delta x} &\leftarrow {\bf 0} \cr
{\bf P} &\leftarrow {\bf G} {\bf P} {\bf G^T} 
}
\eqmark
$$
where ${\bf G}$ is the Jacobian matrix defined as
$$
{\bf G} = \left[
\matrix{
{\bf I_6} & 0 & 0 \cr
0 & {\bf I} - [{ 1 \over 2 } {\bf \delta \Theta]_x} & 0 \cr
0 & 0 & {\bf I_9}
}
\right].
\eqmark
$$

\sec Implementation tools
This section briefly introduces tools used for implementation: the ROS2 \cite[ros2] framework, C++ and Python languages.

{\bf ROS2 \cite[ros2]} is a set of software libraries and tools for building robot applications. It is open-source, and it consists of drivers for hardware, state-of-the-art algorithms, tools for debugging, visualization, simulation and communications over all of the processes. All applications created in ROS2 are easy to share and are used in the community. It supports the most known and most used programming languages like C++, Python, Java, Lua or Lisp. ROS2 distributions are released to work on operating systems like Ubuntu, MacOs or Windows. Nevertheless, as it is open-source, users usually use it with one Ubuntu distribution, such as 20.04 or 18.04.

The newest version of ROS is ROS2, which was introduced in 2014 at the conference ROSCon 2014 in Chicago \cite[ros2], but the first distribution was released in May 2019. There are several distributions of ROS2 yet, the localization system and experiments are implemented using Foxy Fitzroy\fnote{The documentation to ROS2 Foxy Fitzroy \url{https://docs.ros.org/en/foxy/index.html}} which was released in June 2020\fnote{The list of all distributions of ROS2 \url{https://docs.ros.org/en/galactic/Releases.html}}.

ROS2 has a defined code style and a set of language versions which are recommended to use. The implementation sticks to these rules and uses C++17 and Python3. As the localization needs to be implemented as a real-time application, it is implemented in C++17. Python3 is used for the visualization of experiments results and supporting scripts.



